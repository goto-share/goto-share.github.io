{"pageProps":{"post":{"mdxSource":"var Component=(()=>{var d=Object.create;var r=Object.defineProperty;var c=Object.getOwnPropertyDescriptor;var l=Object.getOwnPropertyNames;var f=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var o=e=>r(e,\"__esModule\",{value:!0});var k=(e,i)=>()=>(i||e((i={exports:{}}).exports,i),i.exports),w=(e,i)=>{o(e);for(var a in i)r(e,a,{get:i[a],enumerable:!0})},p=(e,i,a)=>{if(i&&typeof i==\"object\"||typeof i==\"function\")for(let t of l(i))!u.call(e,t)&&t!==\"default\"&&r(e,t,{get:()=>i[t],enumerable:!(a=c(i,t))||a.enumerable});return e},m=e=>p(o(r(e!=null?d(f(e)):{},\"default\",e&&e.__esModule&&\"default\"in e?{get:()=>e.default,enumerable:!0}:{value:e,enumerable:!0})),e);var h=k((b,s)=>{s.exports=_jsx_runtime});var j={};w(j,{default:()=>x,frontmatter:()=>g});var n=m(h()),g={title:`Apache Kafka: The Definitive Guide | Confluent\n`,date:new Date(16076448e5),draft:!1,tags:[\"kafka\"],summary:`Learn how to take full advantage of Apache Kafka, understand how Kafka works and how it\\u2019s designed with this comprehensive book.\n`};function v(e={}){let{wrapper:i}=e.components||{};return i?(0,n.jsx)(i,Object.assign({},e,{children:(0,n.jsx)(a,{})})):a();function a(){let t=Object.assign({h2:\"h2\",a:\"a\",span:\"span\",p:\"p\",ul:\"ul\",li:\"li\"},e.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(t.h2,{id:\"content\",children:[(0,n.jsx)(t.a,{href:\"#content\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,n.jsx)(t.span,{className:\"icon icon-link\"})}),\"Content\"]}),(0,n.jsx)(t.p,{children:(0,n.jsx)(t.a,{href:\"https://www.confluent.io/resources/kafka-the-definitive-guide/\",children:\"https://www.confluent.io/resources/kafka-the-definitive-guide/\"})}),(0,n.jsxs)(t.h2,{id:\"link-preview\",children:[(0,n.jsx)(t.a,{href:\"#link-preview\",\"aria-hidden\":\"true\",tabIndex:\"-1\",children:(0,n.jsx)(t.span,{className:\"icon icon-link\"})}),\"Link Preview\"]}),(0,n.jsxs)(t.ul,{children:[(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:\"https://www.confluent.io/resources/kafka-the-definitive-guide/\",children:\"https://www.confluent.io/resources/kafka-the-definitive-guide/\"})}),(0,n.jsx)(t.li,{children:\"Apache Kafka: The Definitive Guide | Confluent\"}),(0,n.jsx)(t.li,{children:\"Learn how to take full advantage of Apache Kafka, understand how Kafka works and how it\\u2019s designed with this comprehensive book.\"})]})]})}}var x=v;return j;})();\n;return Component;","toc":[{"value":"Content","url":"#content","depth":2},{"value":"Link Preview","url":"#link-preview","depth":2}],"frontMatter":{"readingTime":{"text":"1 min read","minutes":0.44,"time":26400,"words":88},"slug":"2020-12-11-848","fileName":"2020-12-11-848.mdx","title":"Apache Kafka: The Definitive Guide | Confluent\n","date":"2020-12-11T00:00:00.000Z","draft":false,"tags":["kafka"],"summary":"Learn how to take full advantage of Apache Kafka, understand how Kafka works and how it’s designed with this comprehensive book.\n"}},"authorDetails":[{"readingTime":{"text":"1 min read","minutes":0.36,"time":21600,"words":72},"slug":["default"],"fileName":"default.md","name":"Hao Chen","avatar":"/static/images/avatar.jpg","occupation":"MegaEase Inc. Founder","company":"MegaEase Inc.","email":"haoel@hotmail.com","twitter":"https://twitter.com/haoel","linkedin":"https://www.linkedin.com/in/haoel","github":"https://github.com/haoel","date":null}],"prev":{"title":"分布式事务中的时间戳\n","date":"2020-12-07T00:00:00.000Z","draft":false,"tags":["distributed"],"summary":"时间戳（timestamp）是分布式事务中绕不开的重要概念，有意思的是，现在主流的几个分布式数据库对它的实现都不尽相同，甚至是主要区分点之一。本文聊一聊时间戳的前世今生，为了把讨论集中在主题上，假设读者已经对数据库的 MVCC、2PC、一致性、隔离级别等概念有个基本的了解。\n","slug":"2020-12-07-847"},"next":{"title":"Disaster recovery for multi-region Kafka at Uber | Uber Blog\n","date":"2020-12-22T00:00:00.000Z","draft":false,"tags":["kafka"],"summary":"Uber has one of the largest deployments of Apache Kafka in the world, processing trillions of messages and multiple petabytes of data per day. As Figure 1 shows, today we position Apache Kafka as a cornerstone to Uber’s technology stack and build a complex ecosystem on top of it to empower a large number of different workflows. These include a pub/sub message bus to pass event data from the rider and driver apps, enabling a streaming analytics platform (e.g. Apache Samza, Apache Flink), streaming database changelogs to the downstream subscribers, and ingesting all sorts of data into Uber’s Apache Hadoop data lake.\n","slug":"2020-12-22-849"}},"__N_SSG":true}